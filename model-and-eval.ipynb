{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Modelling and evaluation </h1>\n",
    "<h2> 1. Import and download </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score as ACC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import RNN, Dense, Dropout, BatchNormalization\n",
    "from keras import Sequential, layers, Input, callbacks\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the datasets\n",
    "train_A = pd.read_csv('data/train_A.csv')\n",
    "train_B = pd.read_csv('data/train_B.csv')\n",
    "train_C = pd.read_csv('data/train_C.csv')\n",
    "\n",
    "val_A = pd.read_csv('data/val_A.csv')\n",
    "val_B = pd.read_csv('data/val_B.csv')\n",
    "val_C = pd.read_csv('data/val_C.csv')\n",
    "\n",
    "test_A = pd.read_csv('data/test_A.csv')\n",
    "test_B = pd.read_csv('data/test_B.csv')\n",
    "test_C = pd.read_csv('data/test_C.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. Data preprocessing </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [train_A, val_A, test_A, \n",
    "            train_B, val_B, test_B, \n",
    "            train_C, val_C, test_C]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "imp_char = [\"FRODO\", \"SAM\", \"GANDALF\", \"PIPPIN\", \"MERRY\", \"GOLLUM\", \"GIMLI\", \"THEODEN\", \"FARAMIR\", \"ARAGORN\"]\n",
    "\n",
    "# Creating a common label for the characters not of interest\n",
    "def common_label_removal(data):\n",
    "    mask = data[\"char\"].isin(imp_char)\n",
    "    data.loc[~ mask, \"char\"] = \"Rest\"\n",
    "    mask2 = data['char'] == 'Rest'\n",
    "    data = data[~mask2]\n",
    "    return data\n",
    "\n",
    "def x_y_split(data):\n",
    "    y_data = data['char']\n",
    "    x_data = data.drop(columns=['char', 'dialog'])\n",
    "    return x_data, y_data\n",
    "\n",
    "def char_2_num(y_data):\n",
    "    encoder = LabelEncoder()\n",
    "    y_data = y_data.values.reshape(-1, 1)\n",
    "    encoded_data = encoder.fit_transform(y_data)\n",
    "    names = list(encoder.inverse_transform(np.unique(encoded_data)))\n",
    "    print(names)\n",
    "    print(np.unique(encoded_data))\n",
    "    return encoded_data, names\n",
    "\n",
    "def preprocessing(data):\n",
    "    data = common_label_removal(data)\n",
    "    x_data, y_data = x_y_split(data)\n",
    "    y_data = char_2_num(y_data)\n",
    "    return x_data, y_data\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    datasets[i] = preprocessing(datasets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_tra_X =datasets[0][0]\n",
    "A_tra_y =datasets[0][1][0]\n",
    "A_val_X =datasets[1][0]\n",
    "A_val_y=datasets[1][1][0]\n",
    "A_tar_X=datasets[2][0]\n",
    "A_tar_y=datasets[2][1][0]\n",
    "\n",
    "B_tra_X =datasets[3][0]\n",
    "B_tra_y =datasets[3][1][0]\n",
    "B_val_X =datasets[4][0]\n",
    "B_val_y=datasets[4][1][0]\n",
    "B_tar_X=datasets[5][0]\n",
    "B_tar_y=datasets[5][1][0]\n",
    "\n",
    "C_tra_X =datasets[6][0]\n",
    "C_tra_y =datasets[6][1][0]\n",
    "C_val_X =datasets[7][0]\n",
    "C_val_y=datasets[7][1][0]\n",
    "C_tar_X=datasets[8][0]\n",
    "C_tar_y=datasets[8][1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. Benchmarks </h2>\n",
    "<h3> 2.1 Naive Benchmark, Monte Carlo Method </h3>\n",
    "<p> Using 1000 simulations with random guesses on target labels. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_benchmark_MonC(y):\n",
    "    accuracy_list = []\n",
    "    for i in range(0,1000,1):\n",
    "        naive_rand_pred = np.random.randint(0,12,size=(len(y)))\n",
    "        accuracy_sel = ACC(naive_rand_pred, y)\n",
    "        accuracy_list.append(accuracy_sel)\n",
    "    return np.mean(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08397863247863248"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_benchmark_MonC(A_tar_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.2 Naive Benchmark, Majority Class Method </h3>\n",
    "<p> Using Frodo, which equals label 2, as guess </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_benchmark_MajC(y):\n",
    "    pred_MCNB =np.repeat(2,len(y))\n",
    "    return ACC(pred_MCNB, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1752136752136752"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_benchmark_MajC(A_tar_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3. Modelling  </h2>\n",
    "<h3> 3.1 ANN on dataset A</h3>\n",
    "<p> Dataset A contains various numerical retrieved from the characters. </p>\n",
    "<p> The feedforward neural network has a relative simple architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "A1 = scaler.fit_transform(A_tra_X)\n",
    "A2 = scaler.transform(A_val_X)\n",
    "A3 = scaler.transform(A_tar_X)\n",
    "\n",
    "Y1 = np.eye(10)[A_tra_y]\n",
    "Y2 = np.eye(10)[A_val_y]\n",
    "Y3 = np.eye(10)[A_tar_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann_model = keras.Sequential([\n",
    "#     layers.Dense(8, activation='relu',input_dim=20),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(rate=0.3),\n",
    "#     # layers.Dense(16, activation='selu'),\n",
    "#     # layers.BatchNormalization(),\n",
    "#     # layers.Dropout(0.3),\n",
    "#     layers.Dense(10, activation='softmax'),\n",
    "#     layers.Dense(10)\n",
    "# ])\n",
    "\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "# ann_model.compile(optimizer=optimizer,\n",
    "#               loss = 'categorical_crossentropy',\n",
    "#               metrics=['accuracy']\n",
    "#               )\n",
    "\n",
    "# early_stopping = callbacks.EarlyStopping(\n",
    "#     min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "#     patience=35, # how many epochs to wait before stopping\n",
    "#     restore_best_weights=True,\n",
    "# )\n",
    "# ann_model.fit(A1, Y1, \n",
    "#           validation_data= (A2, Y2),\n",
    "#           epochs=200, batch_size=10, \n",
    "#           callbacks=early_stopping,\n",
    "#           verbose=0\n",
    "#           )\n",
    "\n",
    "# print('Accuracy train: ',ann_model.evaluate(A1, Y1))\n",
    "# print('Accuracy validation: ',ann_model.evaluate(A2, Y2))\n",
    "# print('Accuracy test: ',ann_model.evaluate(A3, Y3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier \n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_g = {\n",
    "    'objective':['multi:softprob'],\n",
    "    'alpha': hp.uniform('alpha',0,1),\n",
    "    'gamma': hp.uniform('gamma',0,9),\n",
    "    'reg_lambda':hp.quniform('reg_lamda',0,3,1),\n",
    "    'max_depth':hp.quniform('max_depth',6,12,1),\n",
    "    'learning_rate': hp.uniform('learning_rate',0.001,0.05),\n",
    "    'n_estimators': hp.quniform('n_estimators', 5,500,1),\n",
    "    'min_child_weight': hp.quniform('min_child_weight',0,5,1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "    'seed':42\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:                                                \n",
      "0.2083387127397                                       \n",
      "Score:                                                                        \n",
      "0.15518891209417124                                                           \n",
      "Score:                                                                        \n",
      "0.16041389785456617                                                           \n",
      "Score:                                                                        \n",
      "0.19093221947977976                                                           \n",
      "Score:                                                                        \n",
      "0.19003987089424718                                                           \n",
      "Score:                                                                        \n",
      "0.21621036643250427                                                           \n",
      "Score:                                                                            \n",
      "0.1908980444275679                                                                \n",
      "Score:                                                                            \n",
      "0.17957850768938674                                                               \n",
      "Score:                                                                            \n",
      "0.16739320296183785                                                               \n",
      "Score:                                                                            \n",
      "0.17958230491741028                                                               \n",
      "Score:                                                                             \n",
      "0.14647047655211695                                                                \n",
      "Score:                                                                             \n",
      "0.2066413518131764                                                                 \n",
      "Score:                                                                             \n",
      "0.14472375166128726                                                                \n",
      "Score:                                                                             \n",
      "0.16214163660527814                                                                \n",
      "Score:                                                                             \n",
      "0.1978963356749573                                                                 \n",
      "Score:                                                                             \n",
      "0.20312132143535222                                                                \n",
      "Score:                                                                             \n",
      "0.1473438389975318                                                                 \n",
      "Score:                                                                             \n",
      "0.20661477121701158                                                                \n",
      "Score:                                                                             \n",
      "0.1699791152458705                                                                 \n",
      "Score:                                                                             \n",
      "0.21007784317448266                                                                \n",
      "Score:                                                                             \n",
      "0.19527624833871274                                                                \n",
      "Score:                                                                             \n",
      "0.2057300170875261                                                                 \n",
      "Score:                                                                             \n",
      "0.2083652933358648                                                                 \n",
      "Score:                                                                             \n",
      "0.20398329219669642                                                                \n",
      "Score:                                                                             \n",
      "0.21008543763052973                                                                \n",
      "Score:                                                                             \n",
      "0.19439908866527436                                                                \n",
      "Score:                                                                             \n",
      "0.2005392063793431                                                                 \n",
      "Score:                                                                             \n",
      "0.20314030757546991                                                                \n",
      "Score:                                                                             \n",
      "0.14821720144294664                                                                \n",
      "Score:                                                                             \n",
      "0.19788494399088666                                                                \n",
      "Score:                                                                             \n",
      "0.20831972659958234                                                                \n",
      "Score:                                                                             \n",
      "0.20749952534649702                                                                \n",
      "Score:                                                                             \n",
      "0.20576039491171447                                                                \n",
      "Score:                                                                             \n",
      "0.20486045187013482                                                                \n",
      "Score:                                                                             \n",
      "0.2039908866527435                                                                 \n",
      "Score:                                                                             \n",
      "0.1917865957850769                                                                 \n",
      "Score:                                                                             \n",
      "0.19006265426238847                                                                \n",
      "Score:                                                                             \n",
      "0.20312132143535216                                                                \n",
      "Score:                                                                             \n",
      "0.14908676666033796                                                                \n",
      "Score:                                                                             \n",
      "0.18568065312322007                                                                \n",
      "Score:                                                                             \n",
      "0.20749952534649707                                                                \n",
      "Score:                                                                             \n",
      "0.17084868046326185                                                                \n",
      "Score:                                                                             \n",
      "0.1508372887791912                                                                 \n",
      "Score:                                                                             \n",
      "0.20051262578317827                                                                \n",
      "Score:                                                                             \n",
      "0.21099677235617995                                                                \n",
      "Score:                                                                             \n",
      "0.17781659388646287                                                                \n",
      "Score:                                                                             \n",
      "0.21013859882285932                                                                \n",
      "Score:                                                                             \n",
      "0.16389595595215492                                                                \n",
      "Score:                                                                             \n",
      "0.17609265236377442                                                                \n",
      "Score:                                                                             \n",
      "0.2092424530093032                                                                 \n",
      "100%|██████████| 50/50 [01:25<00:00,  1.70s/trial, best loss: -0.21621036643250427]\n"
     ]
    }
   ],
   "source": [
    "def bayopt_xgb(p_g):\n",
    "    internal_model = XGBClassifier(\n",
    "                     objective='multi:softprob',\n",
    "                     alpha=p_g['alpha'],\n",
    "                     gamma=p_g['gamma'],\n",
    "                     reg_lambda= p_g['reg_lambda'],\n",
    "                    #  colsample_bytree= p_q['colsample_bytree'],\n",
    "                     max_depth = int(p_g['max_depth']),\n",
    "                     n_estimator = (p_g['n_estimators']),\n",
    "                     learning_rate=p_g['learning_rate'],\n",
    "                    #  min_child_weight=p_g['min_child_weight'],\n",
    "                     seed =p_g['seed'],\n",
    "                     )\n",
    "    # evaluation = [(A2, A_val_y)]\n",
    "\n",
    "    internal_model.fit(A1, A_tra_y,\n",
    "                     eval_set = [(A2, A_val_y)],\n",
    "                     eval_metric = 'mlogloss',\n",
    "                     early_stopping_rounds=25,verbose=False)\n",
    "    \n",
    "    # pred_valid = internal_model.predict(A2)\n",
    "    # score = ACC(pred_valid, A_tra_y)\n",
    "\n",
    "    score =np.mean(cross_val_score(internal_model, A1, A_tra_y, scoring='accuracy', cv=5))\n",
    "    print('Score:', score)\n",
    "    return {'loss':-score, 'status':STATUS_OK}\n",
    "\n",
    "def tune():\n",
    "    trials = Trials()\n",
    "    best_tune = fmin(fn=bayopt_xgb, \n",
    "                    space=p_g,\n",
    "                    algo= tpe.suggest,\n",
    "                    max_evals=50,\n",
    "                    trials=trials)\n",
    "    return best_tune\n",
    "\n",
    "\n",
    "ntune = tune()\n",
    "ntune['n_estimators'] =  int(ntune['n_estimators'])\n",
    "ntune['max_depth'] =  int(ntune['max_depth'])\n",
    "xmodel = XGBClassifier(**ntune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(alpha=0.08406927978583745, base_score=None, booster=None,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6093240149414962, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=1.9618920404414677,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01938948118356131,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=11, max_leaves=None,\n",
       "              min_child_weight=1.0, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=472, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=0.08406927978583745, base_score=None, booster=None,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6093240149414962, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=1.9618920404414677,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01938948118356131,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=11, max_leaves=None,\n",
       "              min_child_weight=1.0, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=472, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(alpha=0.08406927978583745, base_score=None, booster=None,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6093240149414962, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=1.9618920404414677,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01938948118356131,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=11, max_leaves=None,\n",
       "              min_child_weight=1.0, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=472, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmodel.fit(A1, A_tra_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train:  0.4115082824760244\n",
      "Accuracy validation:  0.4115082824760244\n",
      "Accuracy test:  0.2264957264957265\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy train: ',ACC(xmodel.predict(A1),A_tra_y))\n",
    "print('Accuracy validation: ',ACC(xmodel.predict(A2),A_val_y))\n",
    "print('Accuracy test: ',ACC(xmodel.predict(A3),A_tar_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal_model = XGBClassifier(\n",
    "#                             objective='multi:softmax',\n",
    "#                                 #  alpha=p_q['alpha'],\n",
    "#                                 #  gamma=p_q['gamma'],\n",
    "#                                 #  reg_lambda= p_q['reg_lambda'],\n",
    "#                                 #  colsample_bytree= p_q['colsample_bytree'],\n",
    "#                             # max_depth = int(p_g['max_depth']),\n",
    "#                             max_depth = int(3),\n",
    "\n",
    "#                             n_estimator = (p_g['n_estimators']),\n",
    "#                             learning_rate=p_g['learning_rate'],\n",
    "#                             #  min_child_weight=p_g['min_child_weight'],\n",
    "#                             seed =p_g['seed'],\n",
    "#                             )\n",
    "# evaluation = [(A2, A_val_y)]\n",
    "\n",
    "# internal_model.fit(A1, A_tra_y,\n",
    "#                 eval_set = evaluation,\n",
    "#                 eval_metric = 'mlogloss',\n",
    "#                 early_stopping_rounds=25,verbose=False)\n",
    "    \n",
    "# pred_valid = internal_model.predict(A2)\n",
    "# score = ACC(A2, A_tra_y)\n",
    "#     # return pred_valid\n",
    "\n",
    "# print('Score:', score)\n",
    "# {'loss':-score, 'status':STATUS_OK}\n",
    "\n",
    "# def tune():\n",
    "#     trials = Trials()\n",
    "#     best_tune = fmin(fn=internal_model, \n",
    "#                     space=p_g,\n",
    "#                     algo= tpe.suggest,\n",
    "#                     max_evals=200,\n",
    "#                     trials=trials)\n",
    "#     return best_tune\n",
    "\n",
    "\n",
    "# ntune = tune()\n",
    "# ntune['n_estimators'] =  int(ntune['n_estimators'])\n",
    "# ntune['max_depth'] =  int(ntune['max_depth'])\n",
    "# # xmodel = XGBClassifier(**ntune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def cvscore():\n",
    "#     ntune = tune()\n",
    "#     ntune['n_estimators'] =  int(ntune['n_estimators'])\n",
    "#     ntune['max_depth'] =  int(ntune['max_depth'])\n",
    "#     xmodel = XGBClassifier(**ntune, random_state=42)\n",
    "#     cvs = cross_val_score(xmodel, A1, Y1, cv=25,\n",
    "#                          random_state=42)\n",
    "#     cvs.predict\n",
    "#     return cvs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.2 RNN on dataset B </h3>\n",
    "<p> Dataset B contains embeddings(?). This, I need to read myself up on.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Embedding,Dense\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense , Flatten ,Embedding,Input\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = pd.read_csv('data/train_df.csv')\n",
    "B2= pd.read_csv('data/val_df.csv')\n",
    "B3 = pd.read_csv('data/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = common_label_removal(B1).reset_index(drop=True)\n",
    "B2 = common_label_removal(B2).reset_index(drop=True)\n",
    "B3 = common_label_removal(B3).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quote_list(X):\n",
    "    quote_list = []\n",
    "    for quote in range(len(X)):\n",
    "        splitted_quote =  X['dialog'][quote].split()\n",
    "        sequence_list = []\n",
    "        for split in range(len(splitted_quote)):\n",
    "            splitted_word = splitted_quote[split]\n",
    "\n",
    "            word_list = str()\n",
    "            i=0\n",
    "            while i < (len(splitted_word)):\n",
    "                # print(splitted_word[i])\n",
    "                if splitted_word[i].isalpha() == True:\n",
    "                    word_list += splitted_word[i]\n",
    "                i+=1\n",
    "            sequence_list.append(word_list)\n",
    "        quote_list.append(sequence_list)\n",
    "    return quote_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxlen(X):\n",
    "    uni = []\n",
    "    for i in range(len(quote_list)):\n",
    "        for j in range(len(quote_list[i])):\n",
    "            if quote_list[i][j] not in uni:\n",
    "                uni.append(quote_list[i][j])\n",
    "    return len(uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = quote_list(B1)\n",
    "B2 = quote_list(B2)\n",
    "B3 = quote_list(B3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(B1)\n",
    "B1_seq = tokenizer.texts_to_sequences(B1)\n",
    "B2_seq = tokenizer.texts_to_sequences(B2)\n",
    "B3_seq = tokenizer.texts_to_sequences(B3)\n",
    "maxlen = max([len(seq) for seq in B1_seq])\n",
    "\n",
    "\n",
    "B1_padseq = pad_sequences(B1_seq, maxlen=maxlen,padding='post')\n",
    "B2_padseq = pad_sequences(B2_seq, maxlen=maxlen,padding='post')\n",
    "B3_padseq = pad_sequences(B3_seq, maxlen=maxlen,padding='post')\n",
    "\n",
    "B1y = np.eye(10)[B_tra_y]\n",
    "B2y = np.eye(10)[B_val_y]\n",
    "B3y = np.eye(10)[B_tar_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.1209 - loss: 2.3952 - val_accuracy: 0.1299 - val_loss: 2.2504\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1347 - loss: 2.3081 - val_accuracy: 0.0984 - val_loss: 2.2546\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1126 - loss: 2.3298 - val_accuracy: 0.1299 - val_loss: 2.2445\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1236 - loss: 2.2828 - val_accuracy: 0.1299 - val_loss: 2.2578\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1420 - loss: 2.2659 - val_accuracy: 0.1299 - val_loss: 2.2507\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1166 - loss: 2.2792 - val_accuracy: 0.1299 - val_loss: 2.2382\n",
      "Epoch 7/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1379 - loss: 2.2782 - val_accuracy: 0.1299 - val_loss: 2.2472\n",
      "Epoch 8/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1540 - loss: 2.2685 - val_accuracy: 0.1339 - val_loss: 2.2347\n",
      "Epoch 9/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1277 - loss: 2.2881 - val_accuracy: 0.1299 - val_loss: 2.3362\n",
      "Epoch 10/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1242 - loss: 2.2811 - val_accuracy: 0.1299 - val_loss: 3.2836\n",
      "Epoch 11/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1168 - loss: 2.2780 - val_accuracy: 0.1299 - val_loss: 2.6713\n",
      "Epoch 12/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1267 - loss: 2.2610 - val_accuracy: 0.0984 - val_loss: 3.5516\n",
      "Epoch 13/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1326 - loss: 2.2648 - val_accuracy: 0.0787 - val_loss: 2.6620\n",
      "Epoch 14/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1484 - loss: 2.2828 - val_accuracy: 0.0984 - val_loss: 2.9825\n",
      "Epoch 15/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1298 - loss: 2.2588 - val_accuracy: 0.1299 - val_loss: 2.8668\n",
      "Epoch 16/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1236 - loss: 2.2638 - val_accuracy: 0.1299 - val_loss: 3.4068\n",
      "Epoch 17/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1232 - loss: 2.2472 - val_accuracy: 0.1299 - val_loss: 6.7096\n",
      "Epoch 18/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1434 - loss: 2.2788 - val_accuracy: 0.1260 - val_loss: 36.1303\n",
      "Epoch 19/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.1456 - loss: 2.2730 - val_accuracy: 0.1299 - val_loss: 2.4362\n",
      "Epoch 20/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1294 - loss: 2.2664 - val_accuracy: 0.1299 - val_loss: 5.0066\n",
      "Epoch 21/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1218 - loss: 2.2814 - val_accuracy: 0.1299 - val_loss: 3.8729\n",
      "Epoch 22/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1562 - loss: 2.2671 - val_accuracy: 0.1299 - val_loss: 8.1024\n",
      "Epoch 23/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1395 - loss: 2.2244 - val_accuracy: 0.1299 - val_loss: 6.7588\n",
      "Epoch 24/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1303 - loss: 2.2562 - val_accuracy: 0.1299 - val_loss: 6.8078\n",
      "Epoch 25/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.1566 - loss: 2.2424 - val_accuracy: 0.1299 - val_loss: 34.9799\n",
      "Epoch 26/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1738 - loss: 2.2257 - val_accuracy: 0.1299 - val_loss: 53.5275\n",
      "Epoch 27/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1500 - loss: 2.2208 - val_accuracy: 0.1339 - val_loss: 31.0488\n",
      "Epoch 28/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1592 - loss: 2.2236 - val_accuracy: 0.1299 - val_loss: 6.4313\n",
      "Epoch 29/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.1771 - loss: 2.1889 - val_accuracy: 0.0551 - val_loss: 5.1651\n",
      "Epoch 30/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1779 - loss: 2.1748 - val_accuracy: 0.1299 - val_loss: 96.0218\n",
      "Epoch 31/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2005 - loss: 2.1862 - val_accuracy: 0.1299 - val_loss: 43.6735\n",
      "Epoch 32/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1902 - loss: 2.1306 - val_accuracy: 0.1339 - val_loss: 25.6115\n",
      "Epoch 33/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2070 - loss: 2.1002 - val_accuracy: 0.1693 - val_loss: 11.0042\n",
      "Epoch 34/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.2180 - loss: 2.0583 - val_accuracy: 0.1693 - val_loss: 8.2025\n",
      "Epoch 35/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2159 - loss: 2.0343 - val_accuracy: 0.1693 - val_loss: 4.7047\n",
      "Epoch 36/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2417 - loss: 1.9865 - val_accuracy: 0.1654 - val_loss: 3.5835\n",
      "Epoch 37/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2829 - loss: 1.9367 - val_accuracy: 0.1693 - val_loss: 4.1462\n",
      "Epoch 38/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.2819 - loss: 1.9054 - val_accuracy: 0.1693 - val_loss: 3.4760\n",
      "Epoch 39/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2760 - loss: 1.8833 - val_accuracy: 0.1693 - val_loss: 3.5592\n",
      "Epoch 40/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3008 - loss: 1.8449 - val_accuracy: 0.1339 - val_loss: 3.5105\n",
      "Epoch 41/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.2774 - loss: 1.8315 - val_accuracy: 0.1417 - val_loss: 2.8523\n",
      "Epoch 42/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2773 - loss: 1.8221 - val_accuracy: 0.1260 - val_loss: 3.1425\n",
      "Epoch 43/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2878 - loss: 1.8481 - val_accuracy: 0.1378 - val_loss: 2.6565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d80a1a8490>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model = Sequential([\n",
    "    layers.Embedding(input_dim=2500, output_dim=15, input_length=maxlen),\n",
    "    # layers.Flatten(),\n",
    "    layers.LSTM(8,activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0,3),\n",
    "    layers.Dense(32, activation='selu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='gelu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.005)\n",
    "emb_model.compile(optimizer=optimizer, \n",
    "            loss='categorical_crossentropy', \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=35, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "emb_model.fit(B1_padseq,B1y, epochs=100, batch_size=30, \n",
    "        validation_data=(B2_padseq, B2y),\n",
    "        callbacks=early_stopping,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m15\u001b[0m)         │        \u001b[38;5;34m37,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m288\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,788</span> (487.46 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m124,788\u001b[0m (487.46 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,526</span> (162.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,526\u001b[0m (162.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> (832.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m208\u001b[0m (832.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,054</span> (324.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m83,054\u001b[0m (324.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1567 - loss: 2.2568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2551958560943604, 0.14646905660629272]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train accuracy\n",
    "emb_model.evaluate(B1_padseq, B1y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1307 - loss: 2.2342 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2347300052642822, 0.13385826349258423]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "emb_model.evaluate(B2_padseq, B2y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1461 - loss: 2.2180 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2260401248931885, 0.1794871836900711]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test accuracy\n",
    "emb_model.evaluate(B3_padseq, B3y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> sources </p>\n",
    "<ul>\n",
    "<li>https://keras.io/api/models/model/</li>\n",
    "<li>https://towardsdatascience.com/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456</li>\n",
    "<li>https://www.kaggle.com/code/rajmehra03/a-detailed-explanation-of-keras-embedding-layer</li>\n",
    "<li>https://medium.com/@iqra.bismi/understanding-keras-embedding-for-natural-language-processing-9f65a281b1a7</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.3 RFC on dataset C </h3>\n",
    "<p>  Dataset C contains a counter on how many times a specific word have been mentioned in a quote. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [30,35,45,55,65,75,85,95],\n",
    "    'max_depth': [6,9,12,15,18,21,24,27,30],\n",
    "}\n",
    "\n",
    "acc_list = []\n",
    "for n in range(len(param_grid['n_estimators'])):\n",
    "    nE = param_grid['n_estimators'][n]\n",
    "    for d in range(len(param_grid['max_depth'])):\n",
    "        mD = param_grid['max_depth'][d]\n",
    "        \n",
    "        model = RandomForestClassifier(n_estimators=nE, max_depth=mD, random_state=42) \n",
    "        model.fit(C_tra_X,C_tra_y)\n",
    "        X1 = model.predict(C_tra_X)\n",
    "        x2 = model.predict(C_val_X)\n",
    "        acc_list.append(ACC(x2, C_val_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([59], dtype=int64),)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.Series(acc_list)\n",
    "np.where(a==max(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ne 85\n",
    "#md 24\n",
    "rfc_model = RandomForestClassifier(n_estimators=55, max_depth=15,random_state=42)\n",
    "rfc_model.fit(C_tra_X,C_tra_y)\n",
    "predCtrain= rfc_model.predict(C_tra_X)\n",
    "predCval= rfc_model.predict(C_val_X)\n",
    "predCtest= rfc_model.predict(C_tar_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5483870967741935"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train accuracy \n",
    "ACC(predCtrain, C_tra_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2952755905511811"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train accuracy \n",
    "ACC(predCval, C_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3247863247863248"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train accuracy \n",
    "ACC(predCtest, C_tar_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4. Ensemble model </h2>\n",
    "<p> The RFC contains absolutely best results therefore, they will have prioritized votes if there are ties. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann_model\n",
    "# emb_model\n",
    "# rfc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    }
   ],
   "source": [
    "P1 = xmodel.predict(A3)\n",
    "# P1 = pp.argmax(axis=1)\n",
    "\n",
    "pp = emb_model.predict(B3_padseq)\n",
    "P2 = pp.argmax(axis=1)\n",
    "\n",
    "P3 = rfc_model.predict(C_tar_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for i in range(len(P1)):\n",
    "    preds =  [P1[i],P2[i],P3[i]]\n",
    "    if preds[0]==preds[1]:\n",
    "        ans = preds[0]\n",
    "    elif preds[0]==preds[2]:\n",
    "        ans= preds[0]\n",
    "    elif preds[1]==preds[2]:\n",
    "        ans=preds[1]\n",
    "    else:\n",
    "        ans = preds[2]\n",
    "    final_preds.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2692307692307692"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACC(final_preds, A_tar_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 5. Conclusion: </h1>\n",
    "<p> We have used three different datasets trained on three different models. The best individual model is the random forest classifier, which is trained on dummy coded BoW. </p>\n",
    "<br>\n",
    "<p> Furthermore, all the models have been put together in an ensemble model, where the majority class wins. The accuracy of the ensemble model is equal to the accuracy retrieved from the rfc model. This might indicate that there are no documents where the two other models agrees upon another label than the rfc model. In other words; the other models are do not give any type of additional explanatory power other what than the rfc model gives.</p>\n",
    "<br>\n",
    "<p> The upside of the modelling phase is that we have been able to create a model that is better than random guessing by 300% and a model that better than guessing Frodo all the time by approximately 100%. </p>\n",
    "<br>\n",
    "<h1> Biological hazard have left the building at 01:55.  </h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
