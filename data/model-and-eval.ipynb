{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score as ACC\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import RNN, Dense, Dropout, BatchNormalization\n",
    "from keras import Sequential, layers, Input, callbacks\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/train_df\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jakob\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jakob\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Jakob\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jakob\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Jakob\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train_df'"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the datasets\n",
    "train_A = pd.read_csv('data/train_A.csv')\n",
    "train_B = pd.read_csv('data/train_B.csv')\n",
    "train_C = pd.read_csv('data/train_C.csv')\n",
    "\n",
    "val_A = pd.read_csv('data/val_A.csv')\n",
    "val_B = pd.read_csv('data/val_B.csv')\n",
    "val_C = pd.read_csv('data/val_C.csv')\n",
    "\n",
    "test_A = pd.read_csv('data/test_A.csv')\n",
    "test_B = pd.read_csv('data/test_B.csv')\n",
    "test_C = pd.read_csv('data/test_C.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets = [train_A, val_A, test_A, \n",
    "            train_B, val_B, test_B, \n",
    "            train_C, val_C, test_C]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char</th>\n",
       "      <th>dialog</th>\n",
       "      <th>i</th>\n",
       "      <th>a</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>d</th>\n",
       "      <th>o</th>\n",
       "      <th>l</th>\n",
       "      <th>h</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DENETHOR</td>\n",
       "      <td>['son', 'spent', 'line', 'end']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WITCH KING</td>\n",
       "      <td>['break']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MERRY and PIPPIN</td>\n",
       "      <td>['come', 'green', 'dragon']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAM</td>\n",
       "      <td>['special', 'best', 'salt', 'shire']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ELROND</td>\n",
       "      <td>['stranger', 'distant', 'land', 'friend', 'old...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>GANDALF</td>\n",
       "      <td>['inde', 'good', 'yes', 'good']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>SAM</td>\n",
       "      <td>['strider', 'get']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>GANDALF</td>\n",
       "      <td>['know']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>GOLLUM</td>\n",
       "      <td>['dead', 'rotten', 'elv', 'men', 'orcs', 'grea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>GOLLUM</td>\n",
       "      <td>['aaaaahh']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 char                                             dialog    i  \\\n",
       "0            DENETHOR                    ['son', 'spent', 'line', 'end']  0.0   \n",
       "1          WITCH KING                                          ['break']  1.0   \n",
       "2    MERRY and PIPPIN                        ['come', 'green', 'dragon']  NaN   \n",
       "3                 SAM               ['special', 'best', 'salt', 'shire']  NaN   \n",
       "4              ELROND  ['stranger', 'distant', 'land', 'friend', 'old...  NaN   \n",
       "..                ...                                                ...  ...   \n",
       "353           GANDALF                    ['inde', 'good', 'yes', 'good']  NaN   \n",
       "354               SAM                                 ['strider', 'get']  NaN   \n",
       "355           GANDALF                                           ['know']  NaN   \n",
       "356            GOLLUM  ['dead', 'rotten', 'elv', 'men', 'orcs', 'grea...  NaN   \n",
       "357            GOLLUM                                        ['aaaaahh']  NaN   \n",
       "\n",
       "       a    g    r    d    o    l    h    c  \n",
       "0    1.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  \n",
       "1    1.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0  \n",
       "2    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "353  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "354  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "355  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "356  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "357  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[358 rows x 11 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['ARAGORN', 'FARAMIR', 'FRODO', 'GANDALF', 'GIMLI', 'GOLLUM', 'MERRY', 'PIPPIN', 'SAM', 'THEODEN']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "imp_char = [\"FRODO\", \"SAM\", \"GANDALF\", \"PIPPIN\", \"MERRY\", \"GOLLUM\", \"GIMLI\", \"THEODEN\", \"FARAMIR\", \"ARAGORN\"]\n",
    "\n",
    "# Creating a common label for the characters not of interest\n",
    "def common_label_removal(data):\n",
    "    mask = data[\"char\"].isin(imp_char)\n",
    "    data.loc[~ mask, \"char\"] = \"Rest\"\n",
    "    mask2 = data['char'] == 'Rest'\n",
    "    data = data[~mask2]\n",
    "    return data\n",
    "\n",
    "def x_y_split(data):\n",
    "    y_data = data['char']\n",
    "    x_data = data.drop(columns=['char', 'dialog'])\n",
    "    return x_data, y_data\n",
    "\n",
    "def char_2_num(y_data):\n",
    "    encoder = LabelEncoder()\n",
    "    y_data = y_data.values.reshape(-1, 1)\n",
    "    encoded_data = encoder.fit_transform(y_data)\n",
    "    names = list(encoder.inverse_transform(np.unique(encoded_data)))\n",
    "    print(names)\n",
    "    print(np.unique(encoded_data))\n",
    "    return encoded_data, names\n",
    "\n",
    "def preprocessing(data):\n",
    "    data = common_label_removal(data)\n",
    "    x_data, y_data = x_y_split(data)\n",
    "    y_data = char_2_num(y_data)\n",
    "    return x_data, y_data\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    datasets[i] = preprocessing(datasets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>word_9</th>\n",
       "      <th>word_10</th>\n",
       "      <th>...</th>\n",
       "      <th>word_161</th>\n",
       "      <th>word_162</th>\n",
       "      <th>word_163</th>\n",
       "      <th>word_164</th>\n",
       "      <th>word_165</th>\n",
       "      <th>word_166</th>\n",
       "      <th>word_167</th>\n",
       "      <th>word_168</th>\n",
       "      <th>word_169</th>\n",
       "      <th>word_170</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.115310</td>\n",
       "      <td>7.688281</td>\n",
       "      <td>9.286860</td>\n",
       "      <td>7.688242</td>\n",
       "      <td>7.771596</td>\n",
       "      <td>8.520296</td>\n",
       "      <td>9.904340</td>\n",
       "      <td>9.202535</td>\n",
       "      <td>8.142834</td>\n",
       "      <td>8.952360</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.334905</td>\n",
       "      <td>9.189292</td>\n",
       "      <td>9.307186</td>\n",
       "      <td>10.164455</td>\n",
       "      <td>10.622702</td>\n",
       "      <td>9.824760</td>\n",
       "      <td>11.237732</td>\n",
       "      <td>8.705162</td>\n",
       "      <td>9.194898</td>\n",
       "      <td>12.743243</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.472886</td>\n",
       "      <td>7.548090</td>\n",
       "      <td>10.214078</td>\n",
       "      <td>13.348991</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.116848</td>\n",
       "      <td>8.790980</td>\n",
       "      <td>8.506043</td>\n",
       "      <td>9.787569</td>\n",
       "      <td>7.771913</td>\n",
       "      <td>9.307035</td>\n",
       "      <td>7.550519</td>\n",
       "      <td>9.115552</td>\n",
       "      <td>7.722796</td>\n",
       "      <td>6.736122</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.316826</td>\n",
       "      <td>10.031580</td>\n",
       "      <td>9.539154</td>\n",
       "      <td>9.536426</td>\n",
       "      <td>9.331389</td>\n",
       "      <td>9.984630</td>\n",
       "      <td>12.776522</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>8.749244</td>\n",
       "      <td>6.519113</td>\n",
       "      <td>7.443720</td>\n",
       "      <td>7.932528</td>\n",
       "      <td>9.826411</td>\n",
       "      <td>10.804083</td>\n",
       "      <td>8.896856</td>\n",
       "      <td>10.560899</td>\n",
       "      <td>9.064045</td>\n",
       "      <td>8.195283</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>7.784269</td>\n",
       "      <td>8.413539</td>\n",
       "      <td>7.753873</td>\n",
       "      <td>8.329385</td>\n",
       "      <td>9.464520</td>\n",
       "      <td>9.546089</td>\n",
       "      <td>10.911575</td>\n",
       "      <td>13.359749</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>11.961802</td>\n",
       "      <td>8.855804</td>\n",
       "      <td>9.939498</td>\n",
       "      <td>8.334146</td>\n",
       "      <td>9.954555</td>\n",
       "      <td>9.503821</td>\n",
       "      <td>12.866217</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>9.044804</td>\n",
       "      <td>7.706784</td>\n",
       "      <td>10.586007</td>\n",
       "      <td>9.485938</td>\n",
       "      <td>8.543586</td>\n",
       "      <td>10.895023</td>\n",
       "      <td>9.503613</td>\n",
       "      <td>11.318297</td>\n",
       "      <td>7.783121</td>\n",
       "      <td>11.634004</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>11.732788</td>\n",
       "      <td>7.056313</td>\n",
       "      <td>13.205585</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_1     word_2     word_3      word_4      word_5      word_6  \\\n",
       "3     9.115310   7.688281   9.286860    7.688242    7.771596    8.520296   \n",
       "5    10.334905   9.189292   9.307186   10.164455   10.622702    9.824760   \n",
       "7    10.472886   7.548090  10.214078   13.348991  100.000000  100.000000   \n",
       "8     9.116848   8.790980   8.506043    9.787569    7.771913    9.307035   \n",
       "9     7.316826  10.031580   9.539154    9.536426    9.331389    9.984630   \n",
       "..         ...        ...        ...         ...         ...         ...   \n",
       "353   8.749244   6.519113   7.443720    7.932528    9.826411   10.804083   \n",
       "354   7.784269   8.413539   7.753873    8.329385    9.464520    9.546089   \n",
       "355  11.961802   8.855804   9.939498    8.334146    9.954555    9.503821   \n",
       "356   9.044804   7.706784  10.586007    9.485938    8.543586   10.895023   \n",
       "357  11.732788   7.056313  13.205585  100.000000  100.000000  100.000000   \n",
       "\n",
       "         word_7      word_8      word_9     word_10  ...  word_161  word_162  \\\n",
       "3      9.904340    9.202535    8.142834    8.952360  ...       100       100   \n",
       "5     11.237732    8.705162    9.194898   12.743243  ...       100       100   \n",
       "7    100.000000  100.000000  100.000000  100.000000  ...       100       100   \n",
       "8      7.550519    9.115552    7.722796    6.736122  ...       100       100   \n",
       "9     12.776522  100.000000  100.000000  100.000000  ...       100       100   \n",
       "..          ...         ...         ...         ...  ...       ...       ...   \n",
       "353    8.896856   10.560899    9.064045    8.195283  ...       100       100   \n",
       "354   10.911575   13.359749  100.000000  100.000000  ...       100       100   \n",
       "355   12.866217  100.000000  100.000000  100.000000  ...       100       100   \n",
       "356    9.503613   11.318297    7.783121   11.634004  ...       100       100   \n",
       "357  100.000000  100.000000  100.000000  100.000000  ...       100       100   \n",
       "\n",
       "     word_163  word_164  word_165  word_166  word_167  word_168  word_169  \\\n",
       "3         100       100       100       100       100       100       100   \n",
       "5         100       100       100       100       100       100       100   \n",
       "7         100       100       100       100       100       100       100   \n",
       "8         100       100       100       100       100       100       100   \n",
       "9         100       100       100       100       100       100       100   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "353       100       100       100       100       100       100       100   \n",
       "354       100       100       100       100       100       100       100   \n",
       "355       100       100       100       100       100       100       100   \n",
       "356       100       100       100       100       100       100       100   \n",
       "357       100       100       100       100       100       100       100   \n",
       "\n",
       "     word_170  \n",
       "3         100  \n",
       "5         100  \n",
       "7         100  \n",
       "8         100  \n",
       "9         100  \n",
       "..        ...  \n",
       "353       100  \n",
       "354       100  \n",
       "355       100  \n",
       "356       100  \n",
       "357       100  \n",
       "\n",
       "[254 rows x 170 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_tra_X =datasets[0][0]\n",
    "A_tra_y =datasets[0][1][0]\n",
    "A_val_X =datasets[1][0]\n",
    "A_tra_y=datasets[1][1][0]\n",
    "A_tar_X=datasets[2][0]\n",
    "A_tar_y=datasets[2][1][0]\n",
    "\n",
    "B_tra_X =datasets[3][0]\n",
    "B_tra_y =datasets[3][1][0]\n",
    "B_val_X =datasets[4][0]\n",
    "B_val_y=datasets[4][1][0]\n",
    "B_tar_X=datasets[5][0]\n",
    "B_tar_y=datasets[5][1][0]\n",
    "\n",
    "C_tra_X =datasets[6][0]\n",
    "C_tra_y =datasets[6][1][0]\n",
    "C_val_X =datasets[7][0]\n",
    "C_tra_y=datasets[7][1][0]\n",
    "C_tar_X=datasets[8][0]\n",
    "C_tar_y=datasets[8][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>a</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>d</th>\n",
       "      <th>o</th>\n",
       "      <th>l</th>\n",
       "      <th>h</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      i   a   g   r   d   o   l   h   c\n",
       "3   NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "5   NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "7   NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "8   NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "9   NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "353 NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "354 NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "355 NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "356 NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "357 NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "\n",
       "[254 rows x 9 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_val_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_benchmark_MonC(y):\n",
    "    accuracy_list = []\n",
    "    for i in range(0,1000,1):\n",
    "        naive_rand_pred = np.random.randint(0,12,size=(len(y)))\n",
    "        accuracy_sel = ACC(naive_rand_pred, y)\n",
    "        accuracy_list.append(accuracy_sel)\n",
    "    return np.mean(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08305128205128205"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_benchmark_MonC(A_tar_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_benchmark_MajC(y):\n",
    "    pred_MCNB =np.repeat(2,len(y))\n",
    "    return ACC(pred_MCNB, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1752136752136752"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_benchmark_MajC(A_tar_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4. Modelling  </h2>\n",
    "<h3> ANN on dataset A</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "A1 = scaler.fit_transform(A_tra_X)\n",
    "A2 = scaler.transform(A_val_X)\n",
    "A3 = scaler.transform(A_tar_X)\n",
    "\n",
    "Y1 = np.eye(11)[A_tra_y]\n",
    "Y2 = np.eye(11)[A_tra_y]\n",
    "Y3 = np.eye(11)[A_tra_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1147, 20)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0814 - loss: 6.8511 - val_accuracy: 0.0968 - val_loss: 6.5929\n",
      "Epoch 2/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0904 - loss: 6.9825 - val_accuracy: 0.0942 - val_loss: 6.3822\n",
      "Epoch 3/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0871 - loss: 6.7383 - val_accuracy: 0.0959 - val_loss: 6.4289\n",
      "Epoch 4/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0815 - loss: 6.1875 - val_accuracy: 0.0924 - val_loss: 6.2460\n",
      "Epoch 5/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0878 - loss: 6.6945 - val_accuracy: 0.0959 - val_loss: 6.3010\n",
      "Epoch 6/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0693 - loss: 6.4726 - val_accuracy: 0.0837 - val_loss: 6.2078\n",
      "Epoch 7/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0677 - loss: 5.7929 - val_accuracy: 0.0689 - val_loss: 6.0944\n",
      "Epoch 8/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0727 - loss: 5.2013 - val_accuracy: 0.0619 - val_loss: 6.4041\n",
      "Epoch 9/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0645 - loss: 6.6121 - val_accuracy: 0.0654 - val_loss: 6.6492\n",
      "Epoch 10/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0528 - loss: 7.4656 - val_accuracy: 0.0567 - val_loss: 7.9724\n",
      "Epoch 11/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0444 - loss: 7.2534 - val_accuracy: 0.0584 - val_loss: 7.8701\n",
      "Epoch 12/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0545 - loss: 8.1209 - val_accuracy: 0.0514 - val_loss: 8.1795\n",
      "Epoch 13/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0713 - loss: 8.2871 - val_accuracy: 0.0567 - val_loss: 8.7351\n",
      "Epoch 14/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0579 - loss: 8.7463 - val_accuracy: 0.0645 - val_loss: 9.8852\n",
      "Epoch 15/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0690 - loss: 9.2502 - val_accuracy: 0.0497 - val_loss: 9.2505\n",
      "Epoch 16/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0585 - loss: 9.8250 - val_accuracy: 0.0575 - val_loss: 9.5532\n",
      "Epoch 17/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0543 - loss: 9.4542 - val_accuracy: 0.0619 - val_loss: 9.1220\n",
      "Epoch 18/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0669 - loss: 9.1390 - val_accuracy: 0.0558 - val_loss: 8.6205\n",
      "Epoch 19/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0553 - loss: 7.5539 - val_accuracy: 0.0506 - val_loss: 7.2479\n",
      "Epoch 20/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0635 - loss: 6.8656 - val_accuracy: 0.0471 - val_loss: 8.3637\n",
      "Epoch 21/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0609 - loss: 8.3329 - val_accuracy: 0.0445 - val_loss: 9.0125\n",
      "Epoch 22/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0713 - loss: 8.3222 - val_accuracy: 0.0584 - val_loss: 8.6861\n",
      "Epoch 23/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0694 - loss: 8.8844 - val_accuracy: 0.0602 - val_loss: 8.2952\n",
      "Epoch 24/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0639 - loss: 7.6801 - val_accuracy: 0.0602 - val_loss: 7.9609\n",
      "Epoch 25/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0597 - loss: 7.6612 - val_accuracy: 0.0628 - val_loss: 8.8610\n",
      "Epoch 26/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0544 - loss: 8.0570 - val_accuracy: 0.0645 - val_loss: 8.6122\n",
      "Epoch 27/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0529 - loss: 8.6765 - val_accuracy: 0.0654 - val_loss: 8.6710\n",
      "Epoch 28/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0633 - loss: 9.2847 - val_accuracy: 0.0636 - val_loss: 9.5108\n",
      "Epoch 29/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0566 - loss: 9.3612 - val_accuracy: 0.0593 - val_loss: 7.9886\n",
      "Epoch 30/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0617 - loss: 9.0989 - val_accuracy: 0.0610 - val_loss: 8.2214\n",
      "Epoch 31/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0651 - loss: 8.7154 - val_accuracy: 0.0680 - val_loss: 7.3369\n",
      "Epoch 32/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.0664 - loss: 8.1195 - val_accuracy: 0.0593 - val_loss: 7.5684\n",
      "Epoch 33/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0758 - loss: 7.8979 - val_accuracy: 0.0697 - val_loss: 8.0642\n",
      "Epoch 34/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0662 - loss: 8.4167 - val_accuracy: 0.0619 - val_loss: 8.1325\n",
      "Epoch 35/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0569 - loss: 8.2037 - val_accuracy: 0.0593 - val_loss: 8.9117\n",
      "Epoch 36/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0657 - loss: 8.6653 - val_accuracy: 0.0645 - val_loss: 7.4478\n",
      "Epoch 37/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0597 - loss: 8.0482 - val_accuracy: 0.0628 - val_loss: 8.1697\n",
      "Epoch 38/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0713 - loss: 7.5191 - val_accuracy: 0.0558 - val_loss: 8.8800\n",
      "Epoch 39/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0568 - loss: 8.7957 - val_accuracy: 0.0514 - val_loss: 7.0491\n",
      "Epoch 40/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0487 - loss: 6.6548 - val_accuracy: 0.0506 - val_loss: 7.7545\n",
      "Epoch 41/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0563 - loss: 7.6748 - val_accuracy: 0.0532 - val_loss: 7.9457\n",
      "Epoch 42/200\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0659 - loss: 6.8342 - val_accuracy: 0.0541 - val_loss: 7.0603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f83f7b38d0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(8, activation='relu',input_dim=20),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(rate=0.3),\n",
    "    layers.Dense(8, activation='selu'),\n",
    "    # layers.BatchNormalization(),\n",
    "    # layers.Dropout(0.3),\n",
    "    # layers.Dense(254, activation='softmax'),\n",
    "    layers.Dense(11)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=35, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "model.fit(A1, Y1, \n",
    "          validation_data= (A2, Y2),\n",
    "          epochs=200, batch_size=5, \n",
    "          callbacks=early_stopping\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> RNN on dataset B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshaper(X, timeSteps=None):\n",
    "    X = pd.DataFrame(X)\n",
    "    new_Xs = [np.array(X[timeSteps:])]\n",
    "    print(X.shape)\n",
    "\n",
    "    for i in range(1, timeSteps+1,1):\n",
    "        shift_X  = np.array(X.shift(i))\n",
    "        new_Xs.append(shift_X[timeSteps:])\n",
    "\n",
    "    X_reshaped = np.stack(new_Xs, axis=1)\n",
    "    return X_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1 = reshaper()\n",
    "# B2\n",
    "# B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential([\n",
    "#     layers.Dense(8, activation='relu',input_dim=20),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(rate=0.3),\n",
    "#     layers.Dense(8, activation='selu'),\n",
    "#     # layers.BatchNormalization(),\n",
    "#     # layers.Dropout(0.3),\n",
    "#     # layers.Dense(254, activation='softmax'),\n",
    "#     layers.Dense(11)\n",
    "# ])\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss = 'categorical_crossentropy',\n",
    "#               metrics=['accuracy']\n",
    "#               )\n",
    "\n",
    "# early_stopping = callbacks.EarlyStopping(\n",
    "#     min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "#     patience=35, # how many epochs to wait before stopping\n",
    "#     restore_best_weights=True,\n",
    "# )\n",
    "# model.fit(A1, Y1, \n",
    "#           validation_data= (A2, Y2),\n",
    "#           epochs=200, batch_size=5, \n",
    "#           callbacks=early_stopping\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>word_9</th>\n",
       "      <th>word_10</th>\n",
       "      <th>...</th>\n",
       "      <th>word_161</th>\n",
       "      <th>word_162</th>\n",
       "      <th>word_163</th>\n",
       "      <th>word_164</th>\n",
       "      <th>word_165</th>\n",
       "      <th>word_166</th>\n",
       "      <th>word_167</th>\n",
       "      <th>word_168</th>\n",
       "      <th>word_169</th>\n",
       "      <th>word_170</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.936516</td>\n",
       "      <td>11.274338</td>\n",
       "      <td>12.535010</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.807208</td>\n",
       "      <td>7.082729</td>\n",
       "      <td>10.126812</td>\n",
       "      <td>9.273765</td>\n",
       "      <td>7.891686</td>\n",
       "      <td>8.183380</td>\n",
       "      <td>10.324145</td>\n",
       "      <td>7.371899</td>\n",
       "      <td>9.027041</td>\n",
       "      <td>7.104752</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.937764</td>\n",
       "      <td>7.750165</td>\n",
       "      <td>8.915595</td>\n",
       "      <td>8.662035</td>\n",
       "      <td>6.803154</td>\n",
       "      <td>6.460621</td>\n",
       "      <td>11.343762</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.943976</td>\n",
       "      <td>7.265589</td>\n",
       "      <td>10.792604</td>\n",
       "      <td>13.414934</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.383319</td>\n",
       "      <td>8.229084</td>\n",
       "      <td>10.143223</td>\n",
       "      <td>7.550912</td>\n",
       "      <td>9.198028</td>\n",
       "      <td>7.539784</td>\n",
       "      <td>7.757065</td>\n",
       "      <td>8.074544</td>\n",
       "      <td>7.358045</td>\n",
       "      <td>7.983031</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>8.870296</td>\n",
       "      <td>9.705757</td>\n",
       "      <td>7.965269</td>\n",
       "      <td>6.652018</td>\n",
       "      <td>8.039692</td>\n",
       "      <td>8.533687</td>\n",
       "      <td>8.299333</td>\n",
       "      <td>11.232112</td>\n",
       "      <td>12.855322</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>8.342788</td>\n",
       "      <td>7.922681</td>\n",
       "      <td>8.421476</td>\n",
       "      <td>8.497047</td>\n",
       "      <td>9.581614</td>\n",
       "      <td>10.287869</td>\n",
       "      <td>9.037190</td>\n",
       "      <td>7.900794</td>\n",
       "      <td>11.145840</td>\n",
       "      <td>7.884370</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>9.338175</td>\n",
       "      <td>12.174479</td>\n",
       "      <td>7.489946</td>\n",
       "      <td>10.374016</td>\n",
       "      <td>8.709492</td>\n",
       "      <td>8.717413</td>\n",
       "      <td>8.328237</td>\n",
       "      <td>9.383992</td>\n",
       "      <td>6.920962</td>\n",
       "      <td>7.234212</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>9.798004</td>\n",
       "      <td>8.581070</td>\n",
       "      <td>9.354257</td>\n",
       "      <td>13.826755</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>8.133518</td>\n",
       "      <td>10.620996</td>\n",
       "      <td>7.529290</td>\n",
       "      <td>7.960512</td>\n",
       "      <td>9.321564</td>\n",
       "      <td>8.349144</td>\n",
       "      <td>10.677260</td>\n",
       "      <td>9.012439</td>\n",
       "      <td>9.785184</td>\n",
       "      <td>7.911406</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1147 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word_1     word_2     word_3      word_4      word_5      word_6  \\\n",
       "1      7.936516  11.274338  12.535010  100.000000  100.000000  100.000000   \n",
       "2      7.807208   7.082729  10.126812    9.273765    7.891686    8.183380   \n",
       "3      8.937764   7.750165   8.915595    8.662035    6.803154    6.460621   \n",
       "4     10.943976   7.265589  10.792604   13.414934  100.000000  100.000000   \n",
       "5     11.383319   8.229084  10.143223    7.550912    9.198028    7.539784   \n",
       "...         ...        ...        ...         ...         ...         ...   \n",
       "1663   8.870296   9.705757   7.965269    6.652018    8.039692    8.533687   \n",
       "1664   8.342788   7.922681   8.421476    8.497047    9.581614   10.287869   \n",
       "1665   9.338175  12.174479   7.489946   10.374016    8.709492    8.717413   \n",
       "1670   9.798004   8.581070   9.354257   13.826755  100.000000  100.000000   \n",
       "1671   8.133518  10.620996   7.529290    7.960512    9.321564    8.349144   \n",
       "\n",
       "          word_7      word_8      word_9     word_10  ...  word_161  word_162  \\\n",
       "1     100.000000  100.000000  100.000000  100.000000  ...       100       100   \n",
       "2      10.324145    7.371899    9.027041    7.104752  ...       100       100   \n",
       "3      11.343762  100.000000  100.000000  100.000000  ...       100       100   \n",
       "4     100.000000  100.000000  100.000000  100.000000  ...       100       100   \n",
       "5       7.757065    8.074544    7.358045    7.983031  ...       100       100   \n",
       "...          ...         ...         ...         ...  ...       ...       ...   \n",
       "1663    8.299333   11.232112   12.855322  100.000000  ...       100       100   \n",
       "1664    9.037190    7.900794   11.145840    7.884370  ...       100       100   \n",
       "1665    8.328237    9.383992    6.920962    7.234212  ...       100       100   \n",
       "1670  100.000000  100.000000  100.000000  100.000000  ...       100       100   \n",
       "1671   10.677260    9.012439    9.785184    7.911406  ...       100       100   \n",
       "\n",
       "      word_163  word_164  word_165  word_166  word_167  word_168  word_169  \\\n",
       "1          100       100       100       100       100       100       100   \n",
       "2          100       100       100       100       100       100       100   \n",
       "3          100       100       100       100       100       100       100   \n",
       "4          100       100       100       100       100       100       100   \n",
       "5          100       100       100       100       100       100       100   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1663       100       100       100       100       100       100       100   \n",
       "1664       100       100       100       100       100       100       100   \n",
       "1665       100       100       100       100       100       100       100   \n",
       "1670       100       100       100       100       100       100       100   \n",
       "1671       100       100       100       100       100       100       100   \n",
       "\n",
       "      word_170  \n",
       "1          100  \n",
       "2          100  \n",
       "3          100  \n",
       "4          100  \n",
       "5          100  \n",
       "...        ...  \n",
       "1663       100  \n",
       "1664       100  \n",
       "1665       100  \n",
       "1670       100  \n",
       "1671       100  \n",
       "\n",
       "[1147 rows x 170 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_tra_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_df\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 917\n'y' sizes: 10\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[0;32m     21\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test_padded, y_test)\n",
      "File \u001b[1;32mc:\\Users\\Jakob\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Jakob\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\data_adapter_utils.py:114\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    110\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 917\n'y' sizes: 10\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_padded = pad_sequences(A_tra_X.values, dtype='float32', padding='post')\n",
    "\n",
    "# Example labels (replace with your actual labels)\n",
    "y = np.array([0, 1, 0, 1, 1, 0, 0, 1, 1, 0])\n",
    "\n",
    "# Define RNN model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=170, output_dim=11, input_length=10),\n",
    "    LSTM(units=32),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_padded, y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_new_data_padded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
